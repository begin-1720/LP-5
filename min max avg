!nvcc --version

!pip install git+https://github.com/afnan47/cuda.git

%load_ext nvcc_plugin


%%writefile sum.cu
#include <iostream>
#include <vector>
#include <climits>
__global__ void min_reduction_kernel(int* arr, int size, int* result) {
int tid = blockIdx.x * blockDim.x + threadIdx.x;
if (tid < size) {
atomicMin(result, arr[tid]);
}
}
__global__ void max_reduction_kernel(int* arr, int size, int* result) {
int tid = blockIdx.x * blockDim.x + threadIdx.x;
if (tid < size) {
atomicMax(result, arr[tid]);
}
}
__global__ void sum_reduction_kernel(int* arr, int size, int* result) {
int tid = blockIdx.x * blockDim.x + threadIdx.x;
if (tid < size) {
atomicAdd(result, arr[tid]);
}
}
__global__ void average_reduction_kernel(int* arr, int size, int* sum) {
int tid = blockIdx.x * blockDim.x + threadIdx.x;
if (tid < size) {
atomicAdd(sum, arr[tid]);
}
}
int main() {
int size;
std::cout << "Enter the size of the array: ";
std::cin >> size;
std::vector<int> arr(size);
for (int i = 0; i < size; ++i) {
std::cout << "Enter element " << i << ": ";
std::cin >> arr[i];
}
int* d_arr;
int* d_result;
int result_min = INT_MAX;
int result_max = INT_MIN;
int result_sum = 0;
// Allocate memory on the device
cudaMalloc(&d_arr, size * sizeof(int));
cudaMalloc(&d_result, sizeof(int));
// Copy data from host to device
cudaMemcpy(d_arr, arr.data(), size * sizeof(int),
cudaMemcpyHostToDevice);
cudaMemcpy(d_result, &result_min, sizeof(int), cudaMemcpyHostToDevice);
// Perform min reduction
min_reduction_kernel<<<(size + 255) / 256, 256>>>(d_arr, size,
d_result);
cudaMemcpy(&result_min, d_result, sizeof(int), cudaMemcpyDeviceToHost);
std::cout << "Minimum value: " << result_min << std::endl;
// Perform max reduction
cudaMemcpy(d_result, &result_max, sizeof(int), cudaMemcpyHostToDevice);
max_reduction_kernel<<<(size + 255) / 256, 256>>>(d_arr, size,
d_result);
cudaMemcpy(&result_max, d_result, sizeof(int), cudaMemcpyDeviceToHost);
std::cout << "Maximum value: " << result_max << std::endl;
// Perform sum reduction
cudaMemcpy(d_result, &result_sum, sizeof(int), cudaMemcpyHostToDevice);
sum_reduction_kernel<<<(size + 255) / 256, 256>>>(d_arr, size,
d_result);
cudaMemcpy(&result_sum, d_result, sizeof(int), cudaMemcpyDeviceToHost);
std::cout << "Sum: " << result_sum << std::endl;
// Perform average reduction on CPU side
double average = static_cast<double>(result_sum) / size;
std::cout << "Average: " << average << std::endl;
// Free device memory
cudaFree(d_arr);
cudaFree(d_result);
return 0;
}

!nvcc sum.cu -o sum

!./sum
